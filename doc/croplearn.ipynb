{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "trained-conditioning",
   "metadata": {},
   "source": [
    "## croplearn.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "union-beauty",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0,'../cropseg/')\n",
    "\n",
    "datasetinfo = { \"datadir\":\"/home/ucfaab0/Desktop/su_african_crops_ghana/\",\n",
    "                \"metadatadir\":\"/home/ucfaab0/Desktop/su_african_crops_ghana/metadata/\",\n",
    "                \"dataset\":\"su_african_crops_ghana\",\n",
    "                \"groundcollection\":\"su_african_crops_ghana_labels\",\n",
    "                \"s1collection\":\"su_african_crops_ghana_source_s1\",\n",
    "                \"s2collection\":\"su_african_crops_ghana_source_s2\",\n",
    "                \"groundlabels\":\"su_african_crops_ghana_labels_id.json\",\n",
    "                \"groundmetadata\":\"su_african_crops_ghana_labels.json\",\n",
    "                \"s1metadata\":\"su_african_crops_ghana_source_s1.json\",\n",
    "                \"s2metadata\":\"su_african_crops_ghana_source_s2.json\",\n",
    "                \"groundname\":\"labels.tif\",\n",
    "                \"s1imagename\":\"source.tif\",\n",
    "                \"s2imagename\":\"source.tif\",\n",
    "                \"s2maskname\":\"cloudmask.tif\",\n",
    "                \"groundshape\":[64,64],\n",
    "                \"s1shape\":[64,64],\n",
    "                \"s2shape\":[64,64],\n",
    "                \"extension\":\"tif\"\n",
    "              }\n",
    "s1bands = [\n",
    "            {\"band\":\"vv\",\"idx\":0},\n",
    "            {\"band\":\"vh\",\"idx\":1},    \n",
    "          ]  \n",
    "s2bands = [\n",
    "            {\"band\":\"blue\",\"wavelength\":490,\"idx\":0},\n",
    "            {\"band\":\"green\",\"wavelength\":560,\"idx\":1},\n",
    "            {\"band\":\"red\",\"wavelength\":665,\"idx\":2},\n",
    "            {\"band\":\"rded1\",\"wavelength\":705,\"idx\":3},\n",
    "            {\"band\":\"rded2\",\"wavelength\":740,\"idx\":4},\n",
    "            {\"band\":\"rded3\",\"wavelength\":783,\"idx\":5},\n",
    "            {\"band\":\"nir\",\"wavelength\":842,\"idx\":6},\n",
    "            {\"band\":\"rded4\",\"wavelength\":865,\"idx\":7},\n",
    "            {\"band\":\"swir1\",\"wavelength\":1610,\"idx\":8},\n",
    "            {\"band\":\"swir2\",\"wavelength\":2190,\"idx\":9}\n",
    "          ]\n",
    "s1indices = [\"vhvv\"]\n",
    "s2indices = [\"ndvi\",\"rdedci\",\"ndmi\"]\n",
    "\n",
    "from mlhubdata import loadjson\n",
    "groundlabels = loadjson(f'{datasetinfo[\"metadatadir\"]}{datasetinfo[\"groundlabels\"]}')\n",
    "groundmetadata = loadjson(f'{datasetinfo[\"metadatadir\"]}{datasetinfo[\"groundmetadata\"]}')\n",
    "s1metadata = loadjson(f'{datasetinfo[\"metadatadir\"]}{datasetinfo[\"s1metadata\"]}')\n",
    "s2metadata = loadjson(f'{datasetinfo[\"metadatadir\"]}{datasetinfo[\"s2metadata\"]}')\n",
    "\n",
    "skiplist = [\"001268\",\"002382\",\"003146\",\"003803\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "green-trail",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 / 4040 000282\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../cropseg/satellitedata.py:17: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return (data[nir] - data[red]) / (data[nir] + data[red])\n",
      "../cropseg/satellitedata.py:29: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return (data[nir] / data[reded1]) - 1\n",
      "../cropseg/satellitedata.py:33: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return (data[nir] - data[swir1]) / (data[nir] + data[swir1])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116 / 4040 000430\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../cropseg/satellitedata.py:29: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  return (data[nir] / data[reded1]) - 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "159 / 4040 000249\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../cropseg/compression.py:15: RuntimeWarning: overflow encountered in exp\n",
      "  return A1+A2*(1./(1+numpy.exp(-k1*(x-x01)))-1./(1+numpy.exp(k2*(x-x02))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1072 / 4040 000927\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ucfaab0/.local/lib/python3.8/site-packages/scipy/interpolate/fitpack2.py:232: UserWarning: \n",
      "The maximal number of iterations maxit (set to 20 by the program)\n",
      "allowed for finding a smoothing spline with fp=s has been reached: s\n",
      "too small.\n",
      "There is an approximation returned but the corresponding weighted sum\n",
      "of squared residuals does not satisfy the condition abs(fp-s)/s < tol.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4040 / 4040 004007 003009 0032154040 003729\r"
     ]
    }
   ],
   "source": [
    "#####\n",
    "erosioniterations = 0\n",
    "ncoeff = 15\n",
    "#####\n",
    "\n",
    "import numpy\n",
    "from osgeo import gdal\n",
    "import scipy.interpolate\n",
    "\n",
    "from grounddata import erodedfieldmasks\n",
    "from mlhubdata import get_tileitems_from_collection\n",
    "from satellitedata import load_satellite_data_as_array\n",
    "from satellitedata import load_satellite_cloudmasks_as_array\n",
    "from compression import dct\n",
    "from compression import dct_fittingconditions\n",
    "from compression import doublelogistic\n",
    "from compression import doublelogistic_fittingconditions\n",
    "from compression import doublelogistic_parameterconditions\n",
    "from miscellaneous import fusedataandweight\n",
    "from dates import datepositions\n",
    "\n",
    "coeffs = []\n",
    "for i in range(len(groundmetadata)):\n",
    "    tileid = groundmetadata[i][\"id\"].split(\"_\")[len(groundmetadata[i][\"id\"].split(\"_\"))-1]\n",
    "    print(i+1,\"/\",len(groundmetadata),tileid,end=\"\\r\")\n",
    "    if tileid not in skiplist:\n",
    "        tilehandle = gdal.Open(f'{datasetinfo[\"datadir\"]}{datasetinfo[\"groundcollection\"]}/{datasetinfo[\"groundcollection\"]}_{tileid}/{datasetinfo[\"groundname\"]}')\n",
    "        tiledata = numpy.array(tilehandle.GetRasterBand(1).ReadAsArray(),dtype=\"int\")\n",
    "        crops = numpy.unique(tiledata[tiledata != 0])\n",
    "        fieldmasks = erodedfieldmasks(tiledata,erosioniterations)    \n",
    "        s1items,s1dates = get_tileitems_from_collection(tileid,s1metadata,datasetinfo,verbose=0)\n",
    "        s1data = load_satellite_data_as_array(s1items,s1bands,s1indices,datasetinfo,datasetinfo[\"s1shape\"])\n",
    "        s2items,s2dates = get_tileitems_from_collection(tileid,s2metadata,datasetinfo,verbose=0)\n",
    "        s2data = load_satellite_data_as_array(s2items,s2bands,s2indices,datasetinfo,datasetinfo[\"s2shape\"],rr=4096.)\n",
    "        s2cloudmasks = load_satellite_cloudmasks_as_array(s2items,datasetinfo,datasetinfo[\"s2shape\"])\n",
    "        for j in range(len(fieldmasks)):\n",
    "            for k in range(datasetinfo[\"groundshape\"][0]):\n",
    "                for m in range(datasetinfo[\"groundshape\"][0]):\n",
    "                    if fieldmasks[j][0][k][m] != 0:\n",
    "                        coeff = []                        \n",
    "                        for n in range(len(s2indices)):\n",
    "                            position = len(s2bands) + n\n",
    "                            data = []\n",
    "                            dates = []\n",
    "                            for p in range(len(s2items)):\n",
    "                                if s2cloudmasks[p][k][m] == 0:\n",
    "                                    data.append(s2data[p][position][k][m])\n",
    "                                    dates.append(s2dates[p])                            \n",
    "                            if len(dates) > 0:\n",
    "                                data = numpy.array(data)\n",
    "                                dates = numpy.array(datepositions(dates))                \n",
    "                                if doublelogistic_fittingconditions(dates,data,durationmin=0.9,gapmax=0.33,amplitudemin=0.25) == True:\n",
    "                                    spline = scipy.interpolate.UnivariateSpline(dates,data,s=0.01,k=3)\n",
    "                                    splinedates = numpy.linspace(numpy.min(dates),numpy.max(dates),100)\n",
    "                                    fuseddates,fusedmean,fusedweights = fusedataandweight(dates,data,splinedates,spline(splinedates))                    \n",
    "                                    dbllog = doublelogistic(fuseddates,fusedmean,weights=fusedweights,bound=True,epsilon=0.1)\n",
    "                                    if n == 0:\n",
    "                                        if doublelogistic_parameterconditions(dbllog,A1min=0.11,A1max=0.24,A2min=0.26,A2max=0.63,x01min=0.34,x01max=0.88,k1min=7.65,k1max=54.02,x02min=0.61,x02max=1.08,k2min=-43.89,k2max=-16.52) == True:\n",
    "                                            dbllog = list(dbllog)\n",
    "                                            coeff = coeff + dbllog\n",
    "                                    if n == 1:\n",
    "                                        if doublelogistic_parameterconditions(dbllog,A1min=0.17,A1max=0.41,A2min=0.52,A2max=1.80,x01min=0.34,x01max=0.86,k1min=9.73,k1max=60.25,x02min=0.59,x02max=1.07,k2min=-45.27,k2max=-10.78) == True:\n",
    "                                            dbllog = list(dbllog)\n",
    "                                            coeff = coeff + dbllog\n",
    "                                    if n == 2:\n",
    "                                        if doublelogistic_parameterconditions(dbllog,A1min=-0.22,A1max=-0.09,A2min=0.15,A2max=0.49,x01min=0.34,x01max=0.96,k1min=7.88,k1max=84.59,x02min=0.62,x02max=1.08,k2min=-101.88,k2max=-25.03) == True:                                    \n",
    "                                            dbllog = list(dbllog)\n",
    "                                            coeff = coeff + dbllog\n",
    "                        data = []\n",
    "                        dates = []\n",
    "                        for n in range(len(s1items)):\n",
    "                            data.append(s1data[n][2][k][m])\n",
    "                            dates.append(s1dates[n])\n",
    "                        if len(data) > 0:\n",
    "                            data = numpy.array(data)\n",
    "                            dates = numpy.array(datepositions(dates)) \n",
    "                            if numpy.isnan(numpy.sum(data)) == False and numpy.min(data) > -15.0 and numpy.max(data) < 0.0:\n",
    "                                if dct_fittingconditions(dates,data,minduration=0.9,maxgap=0.2) == True:\n",
    "                                    dctcoeff = dct(data,ncoeff)\n",
    "                                    dctcoeff = list(dctcoeff)\n",
    "                                    coeff = coeff + dctcoeff\n",
    "                        if len(coeff) == (18 + ncoeff):\n",
    "                            coeff.insert(0,crops[j])\n",
    "                            coeffs.append(coeff)\n",
    "data = numpy.array(coeffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "catholic-universe",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = numpy.copy(data)\n",
    "numpy.random.shuffle(d)\n",
    "d[:,0] = d[:,0] - 1\n",
    "d0 = d[d[:,0] == 0][:1945]\n",
    "d1 = d[d[:,0] == 1][:1945]\n",
    "d2 = d[d[:,0] == 2][:1945]\n",
    "d3 = d[d[:,0] == 3][:1945]\n",
    "d = numpy.concatenate([d0,d1,d2,d3])\n",
    "numpy.random.shuffle(d)\n",
    "xtrain, ytrain = d[200:,1:],d[200:,0] \n",
    "xtest, ytest = d[:200,1:],d[:200,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "unavailable-taylor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "237/237 [==============================] - 3s 10ms/step - loss: 1.8636 - accuracy: 0.3142\n",
      "Epoch 2/10\n",
      "237/237 [==============================] - 2s 10ms/step - loss: 1.3055 - accuracy: 0.3852\n",
      "Epoch 3/10\n",
      "237/237 [==============================] - 2s 10ms/step - loss: 1.2936 - accuracy: 0.3879\n",
      "Epoch 4/10\n",
      "237/237 [==============================] - 2s 10ms/step - loss: 1.2765 - accuracy: 0.4044\n",
      "Epoch 5/10\n",
      "237/237 [==============================] - 2s 10ms/step - loss: 1.2633 - accuracy: 0.4120\n",
      "Epoch 6/10\n",
      "237/237 [==============================] - 2s 10ms/step - loss: 1.2435 - accuracy: 0.4323\n",
      "Epoch 7/10\n",
      "237/237 [==============================] - 2s 10ms/step - loss: 1.2304 - accuracy: 0.4439\n",
      "Epoch 8/10\n",
      "237/237 [==============================] - 2s 10ms/step - loss: 1.2104 - accuracy: 0.4546\n",
      "Epoch 9/10\n",
      "237/237 [==============================] - 2s 10ms/step - loss: 1.1942 - accuracy: 0.4593\n",
      "Epoch 10/10\n",
      "237/237 [==============================] - 2s 10ms/step - loss: 1.1664 - accuracy: 0.4767\n",
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_71 (Dense)             (None, 128)               4352      \n",
      "_________________________________________________________________\n",
      "dense_72 (Dense)             (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_73 (Dense)             (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "dense_74 (Dense)             (None, 1024)              525312    \n",
      "_________________________________________________________________\n",
      "dense_75 (Dense)             (None, 2056)              2107400   \n",
      "_________________________________________________________________\n",
      "dense_76 (Dense)             (None, 4)                 8228      \n",
      "=================================================================\n",
      "Total params: 2,809,900\n",
      "Trainable params: 2,809,900\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "model = tf.keras.Sequential([\n",
    "    layers.Dense(128,activation='relu'),\n",
    "    layers.Dense(256,activation='relu'),\n",
    "    layers.Dense(512,activation='relu'),\n",
    "    layers.Dense(1024,activation='relu'),\n",
    "    layers.Dense(2056,activation='relu'),\n",
    "    layers.Dense(4)\n",
    "])\n",
    "model.compile(optimizer='Adam',loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),metrics=['accuracy'])\n",
    "model.fit(xtrain,ytrain,epochs=10)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "israeli-waters",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 4ms/step - loss: 1.2337 - accuracy: 0.5100\n",
      "[0.55769231 0.4        0.61682243 0.44680851] 0.5003536105969989\n",
      "0.3490534706077716\n"
     ]
    }
   ],
   "source": [
    "import sklearn.metrics\n",
    "model.evaluate(xtest,ytest,verbose=1)\n",
    "predictions = model.predict(xtest)\n",
    "predict = numpy.argmax(predictions,axis = 1)\n",
    "true = numpy.array(ytest,dtype=int)\n",
    "print(sklearn.metrics.f1_score(true,predict,average=None),sklearn.metrics.f1_score(true,predict,average=\"weighted\"))\n",
    "print(sklearn.metrics.cohen_kappa_score(true,predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "sized-wings",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.185\n",
      "[0.17582418 0.22222222 0.17307692 0.16494845] 0.1843193547574991\n",
      "-0.08543650529400004\n"
     ]
    }
   ],
   "source": [
    "import sklearn.dummy\n",
    "dummy = sklearn.dummy.DummyClassifier(strategy=\"uniform\")\n",
    "dummy.fit(xtrain,ytrain)\n",
    "predict = dummy.predict(xtest)\n",
    "true = numpy.array(ytest,dtype=int)\n",
    "print(sklearn.metrics.accuracy_score(true,predict))\n",
    "print(sklearn.metrics.f1_score(true,predict,average=None),sklearn.metrics.f1_score(true,predict,average=\"weighted\"))\n",
    "print(sklearn.metrics.cohen_kappa_score(true,predict))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
