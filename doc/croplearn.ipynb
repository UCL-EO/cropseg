{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "compliant-estate",
   "metadata": {},
   "source": [
    "## croplearn.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "mounted-girlfriend",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0,'../cropseg/')\n",
    "\n",
    "datasetinfo = { \"datadir\":\"/home/ucfaab0/Desktop/su_african_crops_ghana/\",\n",
    "                \"metadatadir\":\"/home/ucfaab0/Desktop/su_african_crops_ghana/metadata/\",\n",
    "                \"dataset\":\"su_african_crops_ghana\",\n",
    "                \"groundcollection\":\"su_african_crops_ghana_labels\",\n",
    "                \"s1collection\":\"su_african_crops_ghana_source_s1\",\n",
    "                \"s2collection\":\"su_african_crops_ghana_source_s2\",\n",
    "                \"groundlabels\":\"su_african_crops_ghana_labels_id.json\",\n",
    "                \"groundmetadata\":\"su_african_crops_ghana_labels.json\",\n",
    "                \"s1metadata\":\"su_african_crops_ghana_source_s1.json\",\n",
    "                \"s2metadata\":\"su_african_crops_ghana_source_s2.json\",\n",
    "                \"groundname\":\"labels.tif\",\n",
    "                \"s1imagename\":\"source.tif\",\n",
    "                \"s2imagename\":\"source.tif\",\n",
    "                \"s2maskname\":\"cloudmask.tif\",\n",
    "                \"groundshape\":[64,64],\n",
    "                \"s1shape\":[64,64],\n",
    "                \"s2shape\":[64,64],\n",
    "                \"extension\":\"tif\"\n",
    "              }\n",
    "s1bands = [\n",
    "            {\"band\":\"vv\",\"idx\":0},\n",
    "            {\"band\":\"vh\",\"idx\":1},    \n",
    "          ]  \n",
    "s2bands = [\n",
    "            {\"band\":\"blue\",\"wavelength\":490,\"idx\":0},\n",
    "            {\"band\":\"green\",\"wavelength\":560,\"idx\":1},\n",
    "            {\"band\":\"red\",\"wavelength\":665,\"idx\":2},\n",
    "            {\"band\":\"rded1\",\"wavelength\":705,\"idx\":3},\n",
    "            {\"band\":\"rded2\",\"wavelength\":740,\"idx\":4},\n",
    "            {\"band\":\"rded3\",\"wavelength\":783,\"idx\":5},\n",
    "            {\"band\":\"nir\",\"wavelength\":842,\"idx\":6},\n",
    "            {\"band\":\"rded4\",\"wavelength\":865,\"idx\":7},\n",
    "            {\"band\":\"swir1\",\"wavelength\":1610,\"idx\":8},\n",
    "            {\"band\":\"swir2\",\"wavelength\":2190,\"idx\":9}\n",
    "          ]\n",
    "s1indices = [\"vhvv\"]\n",
    "s2indices = [\"ndvi\",\"rdedci\",\"ndmi\"]\n",
    "\n",
    "from mlhubdata import loadjson\n",
    "groundlabels = loadjson(f'{datasetinfo[\"metadatadir\"]}{datasetinfo[\"groundlabels\"]}')\n",
    "groundmetadata = loadjson(f'{datasetinfo[\"metadatadir\"]}{datasetinfo[\"groundmetadata\"]}')\n",
    "s1metadata = loadjson(f'{datasetinfo[\"metadatadir\"]}{datasetinfo[\"s1metadata\"]}')\n",
    "s2metadata = loadjson(f'{datasetinfo[\"metadatadir\"]}{datasetinfo[\"s2metadata\"]}')\n",
    "\n",
    "skiplist = [\"001268\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "focal-conviction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 / 4040\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../cropseg/satellitedata.py:17: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return (data[nir] - data[red]) / (data[nir] + data[red])\n",
      "../cropseg/satellitedata.py:29: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return (data[nir] / data[reded1]) - 1\n",
      "../cropseg/satellitedata.py:33: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return (data[nir] - data[swir1]) / (data[nir] + data[swir1])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116 / 4040\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../cropseg/satellitedata.py:29: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  return (data[nir] / data[reded1]) - 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2587 / 4040/ 404040404040\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../cropseg/compression.py:15: RuntimeWarning: overflow encountered in exp\n",
      "  return A1+A2*(1./(1+numpy.exp(-k1*(x-x01)))-1./(1+numpy.exp(k2*(x-x02))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4040 / 4040 4040\r"
     ]
    }
   ],
   "source": [
    "#####\n",
    "erosioniterations = 0\n",
    "vhvv = 2\n",
    "ndvi = 10\n",
    "ncoeff = 15\n",
    "#####\n",
    "\n",
    "import numpy\n",
    "from osgeo import gdal\n",
    "import scipy.interpolate\n",
    "\n",
    "from grounddata import erodedfieldmasks\n",
    "from mlhubdata import get_tileitems_from_collection\n",
    "from satellitedata import load_satellite_data_as_array\n",
    "from satellitedata import load_satellite_cloudmasks_as_array\n",
    "from compression import dct\n",
    "from compression import dct_fittingconditions\n",
    "from compression import doublelogistic\n",
    "from compression import doublelogistic_fittingconditions\n",
    "from compression import doublelogistic_parameterconditions\n",
    "from dates import datepositions\n",
    "\n",
    "data = []\n",
    "for i in range(len(groundmetadata)):\n",
    "    print(i+1,\"/\",len(groundmetadata),end=\"\\r\")\n",
    "    tileid = groundmetadata[i][\"id\"].split(\"_\")[len(groundmetadata[i][\"id\"].split(\"_\"))-1]\n",
    "    if tileid not in skiplist:\n",
    "        tilehandle = gdal.Open(f'{datasetinfo[\"datadir\"]}{datasetinfo[\"groundcollection\"]}/{datasetinfo[\"groundcollection\"]}_{tileid}/{datasetinfo[\"groundname\"]}')\n",
    "        tiledata = numpy.array(tilehandle.GetRasterBand(1).ReadAsArray(),dtype=\"int\")\n",
    "        crops = numpy.unique(tiledata[tiledata != 0])\n",
    "        fieldmasks = erodedfieldmasks(tiledata,erosioniterations)    \n",
    "        s1items,s1dates = get_tileitems_from_collection(tileid,s1metadata,datasetinfo,verbose=0)\n",
    "        s1data = load_satellite_data_as_array(s1items,s1bands,s1indices,datasetinfo,datasetinfo[\"s1shape\"])\n",
    "        s2items,s2dates = get_tileitems_from_collection(tileid,s2metadata,datasetinfo,verbose=0)\n",
    "        s2data = load_satellite_data_as_array(s2items,s2bands,s2indices,datasetinfo,datasetinfo[\"s2shape\"],rr=4096.)\n",
    "        s2cloudmasks = load_satellite_cloudmasks_as_array(s2items,datasetinfo,datasetinfo[\"s2shape\"])\n",
    "        for j in range(len(fieldmasks)):\n",
    "            for k in range(datasetinfo[\"groundshape\"][0]):\n",
    "                for m in range(datasetinfo[\"groundshape\"][0]):\n",
    "                    if fieldmasks[j][0][k][m] != 0:\n",
    "                        s1 = False\n",
    "                        s2 = False\n",
    "                        tmp_s1data = []\n",
    "                        tmp_s1dates = []                        \n",
    "                        tmp_s2data = []\n",
    "                        tmp_s2dates = []\n",
    "                        for n in range(len(s1items)):\n",
    "                            tmp_s1data.append(s1data[n][vhvv][k][m])\n",
    "                            tmp_s1dates.append(s1dates[n])\n",
    "                        if len(tmp_s1data) > 0:\n",
    "                            tmp_s1data = numpy.array(tmp_s1data)\n",
    "                            tmp_s1dpos = numpy.array(datepositions(tmp_s1dates)) \n",
    "                            if numpy.isnan(numpy.sum(tmp_s1data)) == False and numpy.min(tmp_s1data) > -15.0 and numpy.max(tmp_s1data) < 0.0:\n",
    "                                if dct_fittingconditions(tmp_s1dpos,tmp_s1data,minduration=0.9,maxgap=0.2) == True:\n",
    "                                    dctcoeff = dct(tmp_s1data,ncoeff)\n",
    "                                    s1 = True   \n",
    "                        for n in range(len(s2items)):\n",
    "                            if s2cloudmasks[n][k][m] == 0:\n",
    "                                tmp_s2data.append(s2data[n][ndvi][k][m])\n",
    "                                tmp_s2dates.append(s2dates[n])\n",
    "                        if len(tmp_s2data) > 0:\n",
    "                            tmp_s2data = numpy.array(tmp_s2data)\n",
    "                            tmp_s2dpos = numpy.array(datepositions(tmp_s2dates))   \n",
    "                            if numpy.isnan(numpy.sum(tmp_s2data)) == False and doublelogistic_fittingconditions(tmp_s2dpos,tmp_s2data,durationmin=0.9,gapmax=0.5,amplitudemin=0.25) == True:\n",
    "                                tmp_s2dposnew = numpy.linspace(numpy.min(tmp_s2dpos),numpy.max(tmp_s2dpos),1000)\n",
    "                                smoothedspline = scipy.interpolate.UnivariateSpline(tmp_s2dpos,tmp_s2data,s=0.0075,k=2)\n",
    "                                dbllog = doublelogistic(tmp_s2dposnew,smoothedspline(tmp_s2dposnew),bound=True,epsilon=0.1)\n",
    "                                if doublelogistic_parameterconditions(dbllog,A1min=0.05,A1max=0.25,A2min=0.30,A2max=0.80,x01min=0.50,x01max=0.70,k1min=5.0,k1max=50.0,x02min=0.80,x02max=0.95,k2min=-50.0,k2max=-10.0) == True:\n",
    "                                    s2 = True\n",
    "                        if s1 == True and s2 == True:        \n",
    "                            tmp = []\n",
    "                            tmp.append(crops[j])\n",
    "                            for n in range(len(dbllog)):\n",
    "                                tmp.append(dbllog[n])\n",
    "                            for n in range(len(dctcoeff)):\n",
    "                                tmp.append(dctcoeff[n])\n",
    "                            data.append(tmp)\n",
    "data = numpy.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "sophisticated-contact",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = numpy.copy(data)\n",
    "numpy.random.shuffle(d)\n",
    "d[:,0] = d[:,0] - 1\n",
    "d0 = d[d[:,0] == 0][:10965]\n",
    "d1 = d[d[:,0] == 1][:10965]\n",
    "d2 = d[d[:,0] == 2][:10965]\n",
    "d3 = d[d[:,0] == 3][:10965]\n",
    "d = numpy.concatenate([d0,d1,d2,d3])\n",
    "numpy.random.shuffle(d)\n",
    "xtrain, ytrain = d[1000:,1:],d[1000:,0] \n",
    "xtest, ytest = d[:1000,1:],d[:1000,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "realistic-middle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1340/1340 [==============================] - 2s 1ms/step - loss: 1.3806 - accuracy: 0.3486\n",
      "Epoch 2/10\n",
      "1340/1340 [==============================] - 2s 1ms/step - loss: 1.3067 - accuracy: 0.3792\n",
      "Epoch 3/10\n",
      "1340/1340 [==============================] - 2s 1ms/step - loss: 1.2984 - accuracy: 0.3866\n",
      "Epoch 4/10\n",
      "1340/1340 [==============================] - 2s 1ms/step - loss: 1.2915 - accuracy: 0.3973\n",
      "Epoch 5/10\n",
      "1340/1340 [==============================] - 2s 1ms/step - loss: 1.2878 - accuracy: 0.3942\n",
      "Epoch 6/10\n",
      "1340/1340 [==============================] - 2s 1ms/step - loss: 1.2830 - accuracy: 0.3981\n",
      "Epoch 7/10\n",
      "1340/1340 [==============================] - 2s 1ms/step - loss: 1.2798 - accuracy: 0.4031\n",
      "Epoch 8/10\n",
      "1340/1340 [==============================] - 2s 1ms/step - loss: 1.2725 - accuracy: 0.4061\n",
      "Epoch 9/10\n",
      "1340/1340 [==============================] - 2s 1ms/step - loss: 1.2699 - accuracy: 0.4070\n",
      "Epoch 10/10\n",
      "1340/1340 [==============================] - 2s 1ms/step - loss: 1.2636 - accuracy: 0.4121\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_29 (Dense)             (None, 42)                924       \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 63)                2709      \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 84)                5376      \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 4)                 340       \n",
      "=================================================================\n",
      "Total params: 9,349\n",
      "Trainable params: 9,349\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "model = tf.keras.Sequential([\n",
    "    layers.Dense(21*2,activation='relu'),\n",
    "    layers.Dense(21*3,activation='relu'),\n",
    "    layers.Dense(21*4,activation='relu'),\n",
    "    layers.Dense(4)\n",
    "])\n",
    "model.compile(optimizer='Adam',loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),metrics=['accuracy'])\n",
    "model.fit(xtrain,ytrain,epochs=10)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "advance-injection",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 814us/step - loss: 1.2535 - accuracy: 0.4290\n",
      "[0.45945946 0.29561201 0.51072961 0.43222004] 0.42682235360976023\n",
      "0.23668714198822283\n"
     ]
    }
   ],
   "source": [
    "import sklearn.metrics\n",
    "model.evaluate(xtest,ytest,verbose=1)\n",
    "predictions = model.predict(xtest)\n",
    "predict = numpy.argmax(predictions,axis = 1)\n",
    "true = numpy.array(ytest,dtype=int)\n",
    "print(sklearn.metrics.f1_score(true,predict,average=None),sklearn.metrics.f1_score(true,predict,average=\"weighted\"))\n",
    "print(sklearn.metrics.cohen_kappa_score(true,predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "capital-stuart",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.253\n",
      "[0.25       0.23505976 0.26746507 0.25963489] 0.25313069397921384\n",
      "0.004806769978470737\n"
     ]
    }
   ],
   "source": [
    "import sklearn.dummy\n",
    "dummy = sklearn.dummy.DummyClassifier(strategy=\"uniform\")\n",
    "dummy.fit(xtrain,ytrain)\n",
    "predict = dummy.predict(xtest)\n",
    "true = numpy.array(ytest,dtype=int)\n",
    "print(sklearn.metrics.accuracy_score(true,predict))\n",
    "print(sklearn.metrics.f1_score(true,predict,average=None),sklearn.metrics.f1_score(true,predict,average=\"weighted\"))\n",
    "print(sklearn.metrics.cohen_kappa_score(true,predict))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
